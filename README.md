# Linear Network
Contents:
- The linear network doesn't offer much.
- **Softmax(*z*):** in our case, we chose the sigmoid function
- **Deriv_soft(*z*):** this is the derivative of our softmax function, which is simply the derivative of the sigmoid function with respect to z
- **PreNode(*i,W,b*):** this is the function that returns our z-variable
- **Cost(*x,y*):** this function returns how far off the network's estimate was
- **Deriv_cost(*x,y*):** this is the derivative of our cost function, which is the derivative of the cost function in respect with x
- **Output = softmax(*preNode(initial,weight,bias)*):** this is the output generated by the network based on the a initial value, weight, and bias
